{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb8047b3",
   "metadata": {},
   "source": [
    "<img src=\"Local\\imgs\\U1\\banner_fcd.jpg\" alt=\"banner\" width=\"1100\"  height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443d7de2",
   "metadata": {},
   "source": [
    "# <span style=\"color:black;\"><strong>Limpieza y Estretagias de Imputaci√≥n</strong></span>  \n",
    "---\n",
    "<p align=\"right\">\n",
    "  <a href=\"https://colab.research.google.com/github/mariabda2/intro_data_2025/blob/main/FCD_U4_imputacion.ipynb?clone=true\" target=\"_blank\">\n",
    "    <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Abrir en Colab\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "## <span style=\"color:#2F749F;\"><strong>üéØ Objetivos de aprendizaje</strong></span>\n",
    "\n",
    "> ‚úÖ Comprender la **importancia de la imputaci√≥n de datos** en el tratamiento de valores faltantes y su impacto en la calidad del an√°lisis estad√≠stico y predictivo.  \n",
    ">  \n",
    "> ‚úÖ Diferenciar los **tipos de datos faltantes** (MCAR, MAR, MNAR) y reconocer sus implicaciones metodol√≥gicas en la selecci√≥n de estrategias de imputaci√≥n.  \n",
    ">  \n",
    "> ‚úÖ Aplicar m√©todos **simples** (media, mediana, moda, constante) y **avanzados** (KNN, regresi√≥n, MICE, imputaci√≥n m√∫ltiple) para reemplazar valores faltantes en distintos contextos.  \n",
    ">  \n",
    "> ‚úÖ Evaluar la **idoneidad y el sesgo potencial** introducido por las t√©cnicas de imputaci√≥n, comparando resultados antes y despu√©s del tratamiento.  \n",
    ">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4871154",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2F749F;\"><strong>Introducci√≥n</strong></span>\n",
    "\n",
    "La **limpieza de datos** (o *data cleaning*) es el proceso de identificar, corregir o eliminar errores e inconsistencias en un conjunto de datos con el fin de mejorar su calidad y asegurar su utilidad para el an√°lisis ([Rahm & Do, 2000](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=379a09d1efabff918cae5790214e595b7e1cdb14)). Este proceso es esencial en cualquier flujo de trabajo en ciencia de datos, ya que la presencia de datos sucios puede conducir a conclusiones err√≥neas y decisiones inadecuadas.\n",
    "\n",
    "<div style=\"background-color:#e8f4fd; padding:15px; border-radius:8px; font-size:17px;\"> \n",
    "\n",
    "<b>El objetivo es mejorar la calidad del conjunto de datos en t√©rminos de:</b>\n",
    "\n",
    "- **Exactitud:** los valores reflejan la realidad.  \n",
    "- **Completitud:** ausencia de valores faltantes cr√≠ticos.  \n",
    "- **Consistencia:** los datos no se contradicen entre s√≠.  \n",
    "- **Uniformidad:** los formatos est√°n estandarizados.  \n",
    "- **Validez:** los datos cumplen con las reglas del dominio.  \n",
    "\n",
    "</div>\n",
    "\n",
    "A continuaci√≥n, se describen las principales etapas del proceso, incluyendo las estrategias m√°s comunes aplicadas en cada tipo de variable:\n",
    "\n",
    "## **1. Detecci√≥n de valores faltantes**\n",
    "> Identificar celdas vac√≠as, c√≥digos especiales (NA, NULL, ‚Äú?‚Äù) o inconsistencias que representen ausencia de informaci√≥n.  \n",
    "- Utilizar funciones como `df.isnull().sum()` o `df.info()` para cuantificar la magnitud del problema.  \n",
    "- Analizar el **patr√≥n de ausencia** (aleatorio o no aleatorio) mediante pruebas estad√≠sticas o visualizaciones de correlaci√≥n de faltantes (*missingness maps*).  \n",
    "\n",
    "## **2. Eliminaci√≥n de duplicados**\n",
    "> Se eliminan registros id√©nticos o redundantes que podr√≠an sesgar el an√°lisis.  \n",
    "- En Python: `df.drop_duplicates()`  \n",
    "- Tambi√©n puede aplicarse una eliminaci√≥n condicional cuando los duplicados se definen por un subconjunto de columnas clave (por ejemplo, `ID` o `fecha`).  \n",
    "\n",
    "## **3. Correcci√≥n de errores tipogr√°ficos y de codificaci√≥n**\n",
    "> Unificar valores escritos de forma inconsistente.  \n",
    "- Aplicar funciones de normalizaci√≥n (`str.lower()`, `strip()`) y diccionarios de reemplazo,  por ejemplo: ‚ÄúBogot√°‚Äù, ‚Äúbogota‚Äù, ‚ÄúBogota D.C.‚Äù.\n",
    "- En casos m√°s complejos, utilizar medidas de similitud textual (*fuzzy matching*) para estandarizar categor√≠as.  \n",
    "\n",
    "## **4. Normalizaci√≥n de formatos**\n",
    "> Alinear formatos de fechas, unidades de medida, categor√≠as y escalas.  \n",
    "- Convertir tipos de datos (por ejemplo, de texto a num√©rico) para asegurar compatibilidad con algoritmos.  \n",
    "- Ejemplo: transformar \"12/10/25\" a formato ISO (`2025-10-12`).  \n",
    "\n",
    "## **5. Filtrado y tratamiento de valores at√≠picos (outliers)**\n",
    "- Detectar valores que se alejan significativamente del resto mediante:\n",
    "  - **M√©todos univariados:** rango intercuart√≠lico (IQR), z-score.  \n",
    "  - **M√©todos multivariados:** distancia de Mahalanobis o algoritmos de aislamiento (*Isolation Forest*).  \n",
    "- Los valores at√≠picos pueden **eliminarse, truncarse o imputarse** seg√∫n el contexto y la relevancia del dato.  \n",
    "\n",
    "## **6. Selecci√≥n de estrategia de imputaci√≥n**\n",
    "La elecci√≥n del m√©todo depende del tipo de variable y del mecanismo de ausencia:\n",
    "\n",
    "| **Tipo de variable** | **Estrategias de imputaci√≥n** | **Ejemplos de variables** |\n",
    "|----------------------|-------------------------|-----------------------------|\n",
    "| **Num√©ricas** | - Sustituci√≥n por media, mediana o moda<br>- Interpolaci√≥n lineal o polin√≥mica<br>- Imputaci√≥n por KNN<br>- Modelos de regresi√≥n o MICE | Variables continuas como edad, ingresos, temperatura, peso |\n",
    "| **Categ√≥ricas** | - Sustituci√≥n por la moda<br>- Imputaci√≥n por categor√≠a m√°s frecuente dentro de un grupo<br>- Imputaci√≥n por modelo (√°rbol de decisi√≥n, regresi√≥n log√≠stica)<br>- Creaci√≥n de una nueva categor√≠a ‚ÄúDesconocido‚Äù | Variables como g√©nero, nivel educativo, tipo de producto |\n",
    "\n",
    "## **7. Validaci√≥n posterior a la imputaci√≥n**\n",
    "> Verificar que las imputaciones no alteren la estructura estad√≠stica del conjunto de datos.  \n",
    "- Comparar distribuciones antes y despu√©s del proceso.  \n",
    "- Documentar las decisiones tomadas (m√©todo utilizado, variables afectadas, n√∫mero de imputaciones realizadas).  \n",
    "\n",
    "## \n",
    "<div style=\"background-color:#fff9e6; padding:15px; border-radius:8px; font-size:17px;\"> \n",
    "\n",
    "<b>Nota:</b>\n",
    "\n",
    "La imputaci√≥n no consiste √∫nicamente en ‚Äúrellenar vac√≠os‚Äù, sino en **preservar la integridad estad√≠stica** del conjunto de datos. Por ello, se recomienda combinar criterios emp√≠ricos (an√°lisis exploratorio) y te√≥ricos (conocimiento del dominio) para justificar cada decisi√≥n.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f025f633",
   "metadata": {},
   "source": [
    "**Antes de aplicar cualquier t√©cnica de imputaci√≥n, analiza el tipo de variable (num√©rica, categ√≥rica o temporal) y eval√∫a el impacto que la imputaci√≥n puede tener sobre los an√°lisis posteriores o los modelos predictivos.**\n",
    "\n",
    "> **Funciones destacadas utilizadas**\n",
    "\n",
    "| **Funci√≥n / M√©todo** | **Descripci√≥n** | **Ejemplo de uso** |\n",
    "|-----------------------|----------------|--------------------|\n",
    "| `pd.to_datetime()` | Convierte una columna a formato de fecha, permitiendo el manejo de valores no v√°lidos. | `df['A'] = pd.to_datetime(df['A'], errors='coerce')` |\n",
    "| `.isnull()` / `.sum()` | Identifica y contabiliza valores faltantes. | `df.isnull().sum()` |\n",
    "| `.apply()` | Permite aplicar funciones personalizadas a columnas. | `df['A'] = df['A'].apply(lambda x: np.nan if x < 0 else x)` |\n",
    "| `.fillna()` | Imputa valores faltantes con un valor espec√≠fico o estad√≠stico. | `df['A'] = df['A'].fillna(df['A'].median())` |\n",
    "| `.mode()` | Obtiene el valor m√°s frecuente de una columna (moda). | `df['A'].fillna(df['A'].mode()[0])` |\n",
    "| `.interpolate()` | Rellena valores num√©ricos faltantes mediante interpolaci√≥n lineal. | `df['A'] = df['A'].interpolate(method='linear')` |\n",
    "| `.ffill()` / `.bfill()` | Rellena valores faltantes propagando el √∫ltimo valor v√°lido hacia adelante o hacia atr√°s. | `df['A'] = df['A'].ffill()` |\n",
    "| `df.duplicated(keep=False)` | Detecta registros duplicados en el DataFrame, mostrando `True` para todas las repeticiones. | `df[df.duplicated(keep=False)]` |\n",
    "| `get_close_matches()` | Busca coincidencias aproximadas entre cadenas para detectar errores tipogr√°ficos o categor√≠as similares. | `from difflib import get_close_matches`<br>`get_close_matches('Medelin', ['Medell√≠n', 'Bogot√°', 'Cali'])` |\n",
    "| `pd.concat()` | Combina series o DataFrames para comparaci√≥n o uni√≥n de resultados. | `pd.concat([faltantes_antes, faltantes_despues], axis=1)` |\n",
    "| `missingno` | Visualizaci√≥n gr√°fica de valores faltantes. | `import missingno as msno` |\n",
    "| `sklearn.impute` | Imputaci√≥n avanzada (KNN, media, mediana, constante). | `from sklearn.impute import SimpleImputer` |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cd21aa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2F749F;\"><strong>Ejercicio 1. Limpieza e imputaci√≥n de un conjunto de datos mixto</strong></span>\n",
    "\n",
    "#### <span style=\"color:#2F749F;\"><strong>üìã Instrucciones</strong></span>\n",
    "\n",
    "1. Crea el DataFrame base **df** ejecutando el siguiente c√≥digo:\n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Nombre': ['Ana', 'Luis', 'Pedro', None, 'Marta', 'Luis', 'Sof√≠a'],\n",
    "        'Edad': [25, np.nan, 35, 29, -5, 25, None],\n",
    "        'Ciudad': ['Bogot√°', 'Medell√≠n', None, 'Medell√≠n', 'Cali', 'Bogot√°', 'Cali'],\n",
    "        'Ingreso': [3500, 4800, np.nan, 5200, 5100, np.nan, 4700],\n",
    "        'FechaIngreso': ['2023-01-01', '2023-01-05', None, '2023-01-10', '2023-01-12', None, '2023-01-15']\n",
    "    })\n",
    "\n",
    "2. En un nuevo notebook, aplica las etapas del proceso de limpieza e imputaci√≥n de datos que consideres necesarias sobre el DataFrame df. Ten encuenta incluir:\n",
    "    - C√≥digo correctamente comentado y ejecutado.\n",
    "    - Explicaciones breves de cada paso.\n",
    "    - Resultados visuales o estad√≠sticos que evidencien las transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73080d94",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2F749F;\"><strong>Ejercicio 2. Limpieza de duplicados</strong></span>\n",
    "\n",
    "#### <span style=\"color:#2F749F;\"><strong>üìã Instrucciones</strong></span>\n",
    "\n",
    "1. Crea el DataFrame base **df** ejecutando el siguiente c√≥digo:\n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'ID': [101, 102, 102, 103, 104, 104, 104],\n",
    "        'Nombre': ['Ana', 'Luis', 'Luis', 'Marta', 'Carlos', 'Carlos', 'Carlos'],\n",
    "        'Edad': [25, 30, 30, 29, 40, 40, 41],\n",
    "        'Ciudad': ['Bogot√°', 'Cali', 'Cali', 'Medell√≠n', 'Cali', 'Cali', 'Cali'],\n",
    "        'FechaRegistro': ['2023-01-01', '2023-01-05', '2023-01-05', '2023-01-10', \n",
    "                        '2023-01-15', '2023-01-15', '2023-01-16']\n",
    "    })\n",
    "\n",
    "2.  En el mismo notebook anterior, para el nuevo dataframe df, responde a las siguientes preguntas (utilizando python):\n",
    "    - ¬øCu√°l es el total de registros originales?\n",
    "    - ¬øCu√°les y cu√°ntos son los duplicados exactos?\n",
    "    - ¬øCu√°les y cu√°ntos son los duplicados por varias columnas?\n",
    "    - ¬øCu√°ntos registros debes eliminar?\n",
    "    - ¬øCu√°ntos registros quedan despu√©s de la limpieza?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca274a5",
   "metadata": {},
   "source": [
    "## <span style=\"color:#2F749F;\"><strong>Ejercicio 3. Correcci√≥n de errores tipogr√°ficos o de codificaci√≥n</strong></span>\n",
    "\n",
    "#### <span style=\"color:#2F749F;\"><strong>üìã Instrucciones</strong></span>\n",
    "\n",
    "1. Crea el DataFrame base **df** ejecutando el siguiente c√≥digo:\n",
    "    ```python\n",
    "    df = pd.DataFrame({\n",
    "        'Ciudad': ['bogota', 'Bogot√°', 'BOGOTA', 'bogot√°', 'bogata', 'B√≥gota', 'BogoTa', 'Cali', 'cal√≠', 'medell√≠n', 'medellin']\n",
    "    })\n",
    "\n",
    "2.  En el mismo notebook anterior, para el nuevo dataframe df, estandariza la variable ciudad utilizando python. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18e0e07",
   "metadata": {},
   "source": [
    "**Realice commit de su notebook, en la carpeta sesiones pr√°cticas**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7731fd4",
   "metadata": {},
   "source": [
    "# <span style=\"color:#2F749F;\"><strong>Referencias</strong></span>\n",
    "\n",
    "Little, R. J. A., & Rubin, D. B. (2019). [*Statistical analysis with missing data*](https://onlinelibrary.wiley.com/doi/book/10.1002/9781119482260). John Wiley & Sons.  \n",
    "\n",
    "Van Buuren, S. (2018). [*Flexible imputation of missing data*](https://stefvanbuuren.name/fimd/). CRC Press.  \n",
    "\n",
    "Zhang, S. (2011). [*Shell-neighbor method and its application in missing data imputation*](https://link.springer.com/article/10.1007/s10489-009-0207-6#:~:text=The%20SNI%20fills%20in%20an,neighbors%20of%20the%20incomplete%20instance.). *Knowledge-Based Systems, 24*(5), 709‚Äì715.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
